"""
è®­ç»ƒ Qwen-Decision æ¨¡å‹ï¼ˆæ›¿ä»£BERTï¼‰
åŠŸèƒ½: æ ¹æ®å¯¹è¯å†å²å’Œè¯„åˆ†ï¼Œè¾“å‡ºå†³ç­–(action)å’ŒæŒ‡å¯¼å»ºè®®(guidance)

é’ˆå¯¹ RTX 4060 8GB æ˜¾å­˜ä¼˜åŒ–:
- 4bité‡åŒ–
- å°batch size (2)
- æ¢¯åº¦ç´¯ç§¯ (4)
"""

import json
import sys
import io
import torch
from pathlib import Path
from datasets import Dataset
from transformers import (
    AutoTokenizer,
    AutoModelForCausalLM,
    BitsAndBytesConfig,
    TrainingArguments,
    Trainer,
    DataCollatorForSeq2Seq
)
from peft import (
    LoraConfig,
    get_peft_model,
    prepare_model_for_kbit_training,
    TaskType
)
import matplotlib.pyplot as plt

# ä¿®å¤Windowsæ§åˆ¶å°ç¼–ç 
sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')

# é…ç½®
CONFIG = {
    # æ¨¡å‹é…ç½®
    "base_model": "Qwen/Qwen2-1.5B-Instruct",  # ä½¿ç”¨Qwen2ï¼Œä¸éœ€è¦è‡ªå®šä¹‰ä»£ç 
    "max_length": 1024,
    
    # LoRAé…ç½®
    "lora_r": 8,
    "lora_alpha": 16,
    "lora_dropout": 0.05,
    "lora_target_modules": ["q_proj", "k_proj", "v_proj", "o_proj"],
    
    # è®­ç»ƒé…ç½®ï¼ˆé’ˆå¯¹8GBæ˜¾å­˜ä¼˜åŒ– + æ›´å¥½æ”¶æ•›ï¼‰
    "batch_size": 2,              # å°batch
    "gradient_accumulation": 4,   # æ¢¯åº¦ç´¯ç§¯ï¼Œç­‰æ•ˆbatch=8
    "num_epochs": 5,              # å¢åŠ åˆ°5ä¸ªepochs
    "learning_rate": 1.5e-4,      # é™ä½å­¦ä¹ ç‡ï¼Œæ›´ç¨³å®šæ”¶æ•›
    "warmup_steps": 50,           # å‡å°‘warmupï¼Œæ›´å¿«è¿›å…¥å­¦ä¹ 
    "logging_steps": 5,           # æ›´é¢‘ç¹çš„æ—¥å¿—
    "save_steps": 100,            # æ¯100æ­¥ä¿å­˜
    "eval_steps": 10,             # æ¯10æ­¥éªŒè¯ä¸€æ¬¡
    
    # 4bité‡åŒ–é…ç½®
    "use_4bit": True,
    "bnb_4bit_compute_dtype": torch.float16,
    "bnb_4bit_quant_type": "nf4",
    
    # è·¯å¾„
    "train_data": "dual_qwen_data/qwen_decision_train_split.json",
    "val_data": "dual_qwen_data/qwen_decision_val_split.json",
    "output_dir": "checkpoints/qwen_decision_lora",
}

def load_data(filepath):
    """åŠ è½½è®­ç»ƒæ•°æ®"""
    with open(filepath, 'r', encoding='utf-8') as f:
        data = json.load(f)
    return Dataset.from_list(data)

def format_prompt(example):
    """
    æ ¼å¼åŒ–ä¸ºQwençš„å¯¹è¯æ ¼å¼
    ä½¿ç”¨Qwençš„promptæ¨¡æ¿
    """
    instruction = example['instruction']
    input_text = example['input']
    output_text = example.get('output', '')
    
    # Qwen Chatæ ¼å¼
    prompt = f"""<|im_start|>system
{instruction}<|im_end|>
<|im_start|>user
{input_text}<|im_end|>
<|im_start|>assistant
{output_text}<|im_end|>"""
    
    return prompt

def tokenize_function(examples, tokenizer):
    """åˆ†è¯å‡½æ•°"""
    prompts = [format_prompt(ex) for ex in examples]
    
    # åˆ†è¯
    model_inputs = tokenizer(
        prompts,
        max_length=CONFIG["max_length"],
        truncation=True,
        padding=False,  # åŠ¨æ€padding
        return_tensors=None
    )
    
    # è®¾ç½®labelsï¼ˆç”¨äºè®¡ç®—lossï¼‰
    model_inputs["labels"] = model_inputs["input_ids"].copy()
    
    return model_inputs

def print_trainable_parameters(model):
    """æ‰“å°å¯è®­ç»ƒå‚æ•°"""
    trainable_params = 0
    all_params = 0
    for _, param in model.named_parameters():
        all_params += param.numel()
        if param.requires_grad:
            trainable_params += param.numel()
    
    print(f"\nğŸ“Š æ¨¡å‹å‚æ•°ç»Ÿè®¡:")
    print(f"  å¯è®­ç»ƒå‚æ•°: {trainable_params:,} ({100 * trainable_params / all_params:.2f}%)")
    print(f"  æ€»å‚æ•°: {all_params:,}")
    print(f"  èŠ‚çœå‚æ•°: {100 * (all_params - trainable_params) / all_params:.2f}%")

def plot_training_history(trainer, output_path):
    """ç»˜åˆ¶è®­ç»ƒæ›²çº¿ï¼ˆåŒ…å«è®­ç»ƒlosså’ŒéªŒè¯lossï¼‰"""
    log_history = trainer.state.log_history
    
    # æå–è®­ç»ƒloss
    train_steps = []
    train_losses = []
    
    # æå–éªŒè¯loss
    eval_steps = []
    eval_losses = []
    
    for log in log_history:
        if 'loss' in log and 'eval_loss' not in log:
            train_steps.append(log['step'])
            train_losses.append(log['loss'])
        if 'eval_loss' in log:
            eval_steps.append(log['step'])
            eval_losses.append(log['eval_loss'])
    
    # ç»˜å›¾
    fig, ax = plt.subplots(figsize=(12, 7))
    
    # ç»˜åˆ¶è®­ç»ƒloss
    ax.plot(train_steps, train_losses, label='Training Loss', 
            linewidth=2, color='#2E86AB', alpha=0.8)
    
    # ç»˜åˆ¶éªŒè¯loss
    ax.plot(eval_steps, eval_losses, label='Validation Loss', 
            linewidth=2.5, color='#E63946', alpha=0.9, marker='o', 
            markersize=3, markevery=5)
    
    ax.set_xlabel('Steps', fontsize=13, fontweight='bold')
    ax.set_ylabel('Loss', fontsize=13, fontweight='bold')
    ax.set_title('Qwen-Decision Training History', fontsize=16, fontweight='bold', pad=20)
    ax.legend(fontsize=12, loc='upper right', framealpha=0.9)
    ax.grid(True, alpha=0.3, linestyle='--')
    
    # æ·»åŠ æœ€ç»ˆlosså€¼çš„æ–‡æœ¬æ ‡æ³¨
    if train_losses and eval_losses:
        final_train = train_losses[-1]
        final_eval = eval_losses[-1]
        ax.text(0.02, 0.98, f'Final Train Loss: {final_train:.4f}\nFinal Eval Loss: {final_eval:.4f}',
                transform=ax.transAxes, fontsize=11,
                verticalalignment='top', bbox=dict(boxstyle='round', 
                facecolor='wheat', alpha=0.8))
    
    plt.tight_layout()
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    print(f"\nâœ“ è®­ç»ƒæ›²çº¿å·²ä¿å­˜: {output_path}")

def main():
    print("="*60)
    print("ğŸš€ è®­ç»ƒ Qwen-Decision æ¨¡å‹ï¼ˆæ›¿ä»£BERTï¼‰")
    print("="*60)
    
    # æ£€æŸ¥GPU
    if torch.cuda.is_available():
        gpu_name = torch.cuda.get_device_name(0)
        gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
        print(f"\nâœ“ GPU: {gpu_name}")
        print(f"âœ“ æ˜¾å­˜: {gpu_memory:.1f} GB")
    else:
        print("\nâš ï¸  æœªæ£€æµ‹åˆ°GPUï¼Œå°†ä½¿ç”¨CPUè®­ç»ƒï¼ˆä¼šå¾ˆæ…¢ï¼‰")
    
    # åŠ è½½æ•°æ®
    print(f"\nğŸ“¥ åŠ è½½è®­ç»ƒæ•°æ®...")
    train_dataset = load_data(CONFIG["train_data"])
    val_dataset = load_data(CONFIG["val_data"])
    
    print(f"âœ“ è®­ç»ƒé›†: {len(train_dataset)} æ¡")
    print(f"âœ“ éªŒè¯é›†: {len(val_dataset)} æ¡")
    
    # åŠ è½½åˆ†è¯å™¨
    print(f"\nğŸ“¥ åŠ è½½åˆ†è¯å™¨...")
    tokenizer = AutoTokenizer.from_pretrained(
        CONFIG["base_model"],
        padding_side="right"
    )
    
    # Qwen tokenizerå¯èƒ½æ²¡æœ‰pad_token
    if tokenizer.pad_token is None:
        tokenizer.pad_token = tokenizer.eos_token
    
    print(f"âœ“ åˆ†è¯å™¨åŠ è½½å®Œæˆ")
    
    # åˆ†è¯
    print(f"\nğŸ”„ å¯¹æ•°æ®è¿›è¡Œåˆ†è¯...")
    
    def tokenize_batch(examples):
        # å°†å­—å…¸åˆ—è¡¨è½¬æ¢ä¸ºå•ä¸ªexampleçš„åˆ—è¡¨
        batch = []
        for i in range(len(examples['instruction'])):
            batch.append({
                'instruction': examples['instruction'][i],
                'input': examples['input'][i],
                'output': examples['output'][i]
            })
        return tokenize_function(batch, tokenizer)
    
    train_dataset = train_dataset.map(
        tokenize_batch,
        batched=True,
        remove_columns=train_dataset.column_names,
        desc="åˆ†è¯è®­ç»ƒé›†"
    )
    
    val_dataset = val_dataset.map(
        tokenize_batch,
        batched=True,
        remove_columns=val_dataset.column_names,
        desc="åˆ†è¯éªŒè¯é›†"
    )
    
    print(f"âœ“ åˆ†è¯å®Œæˆ")
    
    # 4bité‡åŒ–é…ç½®
    print(f"\nâš™ï¸  é…ç½®4bité‡åŒ–...")
    bnb_config = BitsAndBytesConfig(
        load_in_4bit=CONFIG["use_4bit"],
        bnb_4bit_compute_dtype=CONFIG["bnb_4bit_compute_dtype"],
        bnb_4bit_quant_type=CONFIG["bnb_4bit_quant_type"],
        bnb_4bit_use_double_quant=True,  # åŒé‡é‡åŒ–ï¼Œè¿›ä¸€æ­¥èŠ‚çœæ˜¾å­˜
    )
    
    # åŠ è½½åŸºåº§æ¨¡å‹
    print(f"\nğŸ“¥ åŠ è½½åŸºåº§æ¨¡å‹: {CONFIG['base_model']}")
    print(f"   ä½¿ç”¨4bité‡åŒ–ä»¥èŠ‚çœæ˜¾å­˜...")
    
    model = AutoModelForCausalLM.from_pretrained(
        CONFIG["base_model"],
        quantization_config=bnb_config,
        device_map="auto",
        torch_dtype=torch.float16,
    )
    
    print(f"âœ“ åŸºåº§æ¨¡å‹åŠ è½½å®Œæˆ")
    
    # å‡†å¤‡æ¨¡å‹ä»¥è¿›è¡Œk-bitè®­ç»ƒ
    model = prepare_model_for_kbit_training(model)
    
    # LoRAé…ç½®
    print(f"\nâš™ï¸  é…ç½®LoRA...")
    lora_config = LoraConfig(
        r=CONFIG["lora_r"],
        lora_alpha=CONFIG["lora_alpha"],
        target_modules=CONFIG["lora_target_modules"],
        lora_dropout=CONFIG["lora_dropout"],
        bias="none",
        task_type=TaskType.CAUSAL_LM
    )
    
    # åº”ç”¨LoRA
    model = get_peft_model(model, lora_config)
    print_trainable_parameters(model)
    
    # è®­ç»ƒå‚æ•°
    print(f"\nâš™ï¸  é…ç½®è®­ç»ƒå‚æ•°...")
    training_args = TrainingArguments(
        output_dir=CONFIG["output_dir"],
        num_train_epochs=CONFIG["num_epochs"],
        per_device_train_batch_size=CONFIG["batch_size"],
        per_device_eval_batch_size=CONFIG["batch_size"],
        gradient_accumulation_steps=CONFIG["gradient_accumulation"],
        learning_rate=CONFIG["learning_rate"],
        warmup_steps=CONFIG["warmup_steps"],
        logging_steps=CONFIG["logging_steps"],
        save_steps=CONFIG["save_steps"],
        eval_steps=CONFIG["eval_steps"],  # ä½¿ç”¨ç‹¬ç«‹çš„eval_steps
        eval_strategy="steps",  # æ–°ç‰ˆæœ¬ä½¿ç”¨eval_strategy
        save_strategy="steps",
        load_best_model_at_end=True,
        fp16=True,  # æ··åˆç²¾åº¦è®­ç»ƒ
        gradient_checkpointing=True,  # æ¢¯åº¦æ£€æŸ¥ç‚¹ï¼Œç”¨æ—¶é—´æ¢ç©ºé—´
        optim="paged_adamw_8bit",  # 8bitä¼˜åŒ–å™¨
        max_grad_norm=0.3,
        logging_dir=f"{CONFIG['output_dir']}/logs",
        report_to="none",  # ä¸ä½¿ç”¨wandbç­‰
    )
    
    print(f"âœ“ è®­ç»ƒé…ç½®:")
    print(f"  - Batch size: {CONFIG['batch_size']}")
    print(f"  - æ¢¯åº¦ç´¯ç§¯: {CONFIG['gradient_accumulation']} (ç­‰æ•ˆbatch={CONFIG['batch_size']*CONFIG['gradient_accumulation']})")
    print(f"  - Epochs: {CONFIG['num_epochs']}")
    print(f"  - Learning rate: {CONFIG['learning_rate']}")
    print(f"  - 4bité‡åŒ–: âœ“")
    print(f"  - æ¢¯åº¦æ£€æŸ¥ç‚¹: âœ“")
    print(f"  - é¢„æœŸæ˜¾å­˜: 5-6GB")
    
    # Data Collator
    data_collator = DataCollatorForSeq2Seq(
        tokenizer=tokenizer,
        model=model,
        padding=True
    )
    
    # åˆ›å»ºTrainer
    print(f"\nğŸ”„ åˆå§‹åŒ–è®­ç»ƒå™¨...")
    trainer = Trainer(
        model=model,
        args=training_args,
        train_dataset=train_dataset,
        eval_dataset=val_dataset,
        data_collator=data_collator,
    )
    
    # å¼€å§‹è®­ç»ƒ
    print(f"\n" + "="*60)
    print("ğŸš€ å¼€å§‹è®­ç»ƒ...")
    print("="*60)
    print(f"\né¢„è®¡è®­ç»ƒæ—¶é—´: 3-4å°æ—¶")
    print(f"å¯ä»¥ä½¿ç”¨ nvidia-smi ç›‘æ§æ˜¾å­˜ä½¿ç”¨æƒ…å†µ\n")
    
    try:
        trainer.train()
        
        print(f"\n" + "="*60)
        print("âœ… è®­ç»ƒå®Œæˆï¼")
        print("="*60)
        
        # ä¿å­˜æœ€ç»ˆæ¨¡å‹
        print(f"\nğŸ’¾ ä¿å­˜æ¨¡å‹...")
        trainer.save_model()
        print(f"âœ“ æ¨¡å‹å·²ä¿å­˜è‡³: {CONFIG['output_dir']}")
        
        # ç»˜åˆ¶è®­ç»ƒæ›²çº¿
        plot_path = Path("plots")
        plot_path.mkdir(exist_ok=True)
        plot_training_history(trainer, plot_path / "qwen_decision_training.png")
        
        # æ˜¾ç¤ºæœ€ç»ˆæŒ‡æ ‡
        print(f"\nğŸ“Š æœ€ç»ˆè®­ç»ƒæŒ‡æ ‡:")
        final_metrics = trainer.state.log_history[-1]
        for key, value in final_metrics.items():
            if isinstance(value, float):
                print(f"  {key}: {value:.4f}")
        
        print(f"\nğŸ‰ Qwen-Decision è®­ç»ƒæˆåŠŸï¼")
        print(f"\nä¸‹ä¸€æ­¥:")
        print(f"  1. è¿è¡Œ: python train_qwen_question.py")
        print(f"  2. è®­ç»ƒå®Œæˆåï¼Œä½¿ç”¨: python test_dual_qwen.py è¿›è¡Œæµ‹è¯•")
        
    except KeyboardInterrupt:
        print(f"\n\nâš ï¸  è®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­")
        print(f"æ¨¡å‹checkpointå·²ä¿å­˜è‡³: {CONFIG['output_dir']}")
    except Exception as e:
        print(f"\n\nâŒ è®­ç»ƒå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()

