"""
å‡†å¤‡åŒQwenè®­ç»ƒæ•°æ®
å°†ç°æœ‰çš„BERTå’ŒQwenæ•°æ®è½¬æ¢ä¸ºé€‚åˆQwen-LoRAè®­ç»ƒçš„æ ¼å¼
"""

import json
import sys
import io
from pathlib import Path

# ä¿®å¤Windowsæ§åˆ¶å°ç¼–ç é—®é¢˜
sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')

def load_json(filepath):
    """åŠ è½½JSONæ•°æ®"""
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            return json.load(f)
    except FileNotFoundError:
        print(f"âš ï¸  æ–‡ä»¶æœªæ‰¾åˆ°: {filepath}")
        return []

def prepare_decision_data(bert_data):
    """
    å‡†å¤‡Qwen-Decisionè®­ç»ƒæ•°æ®
    æ›¿ä»£BERTçš„åŠŸèƒ½: è¾“å‡º action + guidance
    
    è¾“å…¥æ ¼å¼ (BERT):
    {
        "topic": "...",
        "round_number": 3,
        "history": [...],
        "scores": [85, 90, 80],
        "avg_score": 85,
        "recent_trend": "stable",
        "action": "FOLLOW_UP",
        "guidance": "..."
    }
    
    è¾“å‡ºæ ¼å¼ (Qwenè®­ç»ƒ):
    {
        "instruction": "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„æŠ€æœ¯é¢è¯•å®˜...",
        "input": "å½“å‰è¯é¢˜: ...\nå¯¹è¯å†å²: ...\nè¯„åˆ†æƒ…å†µ: ...",
        "output": "å†³ç­–: FOLLOW_UP\næŒ‡å¯¼å»ºè®®: ..."
    }
    """
    decision_data = []
    
    for idx, item in enumerate(bert_data):
        # æ„å»ºè¾“å…¥
        topic = item.get('topic', 'æœªçŸ¥è¯é¢˜')
        round_num = item.get('round_number', 0)
        history = item.get('history', [])
        scores = item.get('scores', [])
        avg_score = item.get('avg_score', 0)
        recent_trend = item.get('recent_trend', 'unknown')
        
        # æ ¼å¼åŒ–å¯¹è¯å†å²ï¼ˆæœ€è¿‘3è½®ï¼‰
        history_text = ""
        recent_history = history[-3:] if len(history) > 3 else history
        for h in recent_history:
            q = h.get('question', '')
            a = h.get('answer', '')
            s = h.get('score', 0)
            history_text += f"é—®: {q}\nç­”: {a}\nè¯„åˆ†: {s}åˆ†\n\n"
        
        # æ ¼å¼åŒ–è¯„åˆ†æƒ…å†µ
        score_text = f"å¹³å‡åˆ†: {avg_score}åˆ†\n"
        score_text += f"åˆ†æ•°è¶‹åŠ¿: {recent_trend}\n"
        if scores:
            score_text += f"æœ€è¿‘3æ¬¡: {scores[-3:]}\n"
        
        # æ„å»ºè¾“å…¥æ–‡æœ¬
        input_text = f"""å½“å‰è¯é¢˜: {topic}
å½“å‰è½®æ¬¡: ç¬¬{round_num}è½®

å¯¹è¯å†å²:
{history_text.strip()}

è¯„åˆ†æƒ…å†µ:
{score_text.strip()}

è¯·æ ¹æ®ä»¥ä¸Šä¿¡æ¯ï¼Œåšå‡ºé¢è¯•å†³ç­–å¹¶æä¾›æŒ‡å¯¼å»ºè®®ã€‚"""
        
        # æ„å»ºè¾“å‡ºï¼ˆæ ‡å‡†ç­”æ¡ˆï¼‰
        action = item.get('action', 'SWITCH_TOPIC')
        guidance = item.get('guidance', '...')
        
        output_text = f"""å†³ç­–: {action}

æŒ‡å¯¼å»ºè®®: {guidance}"""
        
        # æ·»åŠ åˆ°è®­ç»ƒæ•°æ®
        decision_data.append({
            "instruction": "ä½ æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œçš„æŠ€æœ¯é¢è¯•å®˜ã€‚ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®å½“å‰é¢è¯•è¯é¢˜ã€å¯¹è¯å†å²å’Œå€™é€‰äººçš„è¡¨ç°è¯„åˆ†ï¼Œåšå‡ºé¢è¯•å†³ç­–ï¼ˆFOLLOW_UPç»§ç»­æ·±å…¥ æˆ– SWITCH_TOPICåˆ‡æ¢è¯é¢˜ï¼‰ï¼Œå¹¶ä¸ºé—®é¢˜ç”Ÿæˆå™¨æä¾›è¯¦ç»†çš„æŒ‡å¯¼å»ºè®®ã€‚",
            "input": input_text,
            "output": output_text
        })
    
    return decision_data

def prepare_question_data(qwen_data):
    """
    å‡†å¤‡Qwen-Questionè®­ç»ƒæ•°æ®
    åŸæœ‰åŠŸèƒ½: è¾“å‡º question + importance
    
    è¾“å…¥æ ¼å¼ (Qwen):
    {
        "topic": "...",
        "full_history": [...],
        "guidance": "...",
        "question": "...",
        "importance": 4
    }
    
    è¾“å‡ºæ ¼å¼ (Qwenè®­ç»ƒ):
    {
        "instruction": "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„æŠ€æœ¯é¢è¯•å®˜...",
        "input": "è¯é¢˜: ...\nå†å²å¯¹è¯: ...\næŒ‡å¯¼å»ºè®®: ...",
        "output": "é—®é¢˜: ...\né‡è¦ç¨‹åº¦: 4"
    }
    """
    question_data = []
    
    for idx, item in enumerate(qwen_data):
        # æ„å»ºè¾“å…¥
        topic = item.get('topic', 'æœªçŸ¥è¯é¢˜')
        full_history = item.get('full_history', [])
        guidance = item.get('guidance', 'è¯·æå‡ºç›¸å…³é—®é¢˜')
        
        # æ ¼å¼åŒ–å®Œæ•´å¯¹è¯å†å²ï¼ˆæ‰€æœ‰è½®æ¬¡ï¼‰
        history_text = ""
        for h in full_history:
            q = h.get('question', '')
            a = h.get('answer', '')
            history_text += f"Q: {q}\nA: {a}\n\n"
        
        # æ„å»ºè¾“å…¥æ–‡æœ¬
        input_text = f"""é¢è¯•è¯é¢˜: {topic}

å®Œæ•´å¯¹è¯å†å²:
{history_text.strip() if history_text else 'ï¼ˆè¿™æ˜¯ç¬¬ä¸€ä¸ªé—®é¢˜ï¼‰'}

å†³ç­–æŒ‡å¯¼:
{guidance}

è¯·æ ¹æ®ä»¥ä¸Šä¿¡æ¯ç”Ÿæˆä¸‹ä¸€ä¸ªé¢è¯•é—®é¢˜ï¼Œå¹¶è¯„ä¼°å…¶é‡è¦ç¨‹åº¦ï¼ˆ1-5åˆ†ï¼‰ã€‚"""
        
        # æ„å»ºè¾“å‡ºï¼ˆæ ‡å‡†ç­”æ¡ˆï¼‰
        question = item.get('question', '')
        importance = item.get('importance', 3)
        
        output_text = f"""é—®é¢˜: {question}

é‡è¦ç¨‹åº¦: {importance}åˆ†"""
        
        # æ·»åŠ åˆ°è®­ç»ƒæ•°æ®
        question_data.append({
            "instruction": "ä½ æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œçš„æŠ€æœ¯é¢è¯•å®˜ã€‚ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®é¢è¯•è¯é¢˜ã€å®Œæ•´å¯¹è¯å†å²å’Œå†³ç­–æŒ‡å¯¼ï¼Œç”Ÿæˆä¸‹ä¸€ä¸ªåˆé€‚çš„é¢è¯•é—®é¢˜ï¼Œå¹¶è¯„ä¼°è¯¥é—®é¢˜çš„é‡è¦ç¨‹åº¦ï¼ˆ1-5åˆ†ï¼Œå…¶ä¸­1åˆ†ä¸ºé—²èŠï¼Œ5åˆ†ä¸ºæ ¸å¿ƒæŠ€èƒ½è€ƒå¯Ÿï¼‰ã€‚",
            "input": input_text,
            "output": output_text
        })
    
    return question_data

def save_json(data, filepath):
    """ä¿å­˜JSONæ•°æ®"""
    with open(filepath, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    print(f"âœ“ å·²ä¿å­˜: {filepath} ({len(data)} æ¡)")

def analyze_data(data, name):
    """åˆ†ææ•°æ®ç»Ÿè®¡ä¿¡æ¯"""
    print(f"\n{'='*60}")
    print(f"ğŸ“Š {name} æ•°æ®ç»Ÿè®¡")
    print(f"{'='*60}")
    print(f"æ€»æ•°æ®é‡: {len(data)}")
    
    if data:
        # è®¡ç®—å¹³å‡é•¿åº¦
        input_lengths = [len(item['input']) for item in data]
        output_lengths = [len(item['output']) for item in data]
        
        print(f"\nè¾“å…¥æ–‡æœ¬:")
        print(f"  å¹³å‡é•¿åº¦: {sum(input_lengths) / len(input_lengths):.0f} å­—ç¬¦")
        print(f"  æœ€çŸ­: {min(input_lengths)} å­—ç¬¦")
        print(f"  æœ€é•¿: {max(input_lengths)} å­—ç¬¦")
        
        print(f"\nè¾“å‡ºæ–‡æœ¬:")
        print(f"  å¹³å‡é•¿åº¦: {sum(output_lengths) / len(output_lengths):.0f} å­—ç¬¦")
        print(f"  æœ€çŸ­: {min(output_lengths)} å­—ç¬¦")
        print(f"  æœ€é•¿: {max(output_lengths)} å­—ç¬¦")
        
        # æ˜¾ç¤ºç¤ºä¾‹
        print(f"\nç¤ºä¾‹æ•°æ® (ç¬¬1æ¡):")
        print(f"\nã€æŒ‡ä»¤ã€‘")
        print(data[0]['instruction'][:100] + "...")
        print(f"\nã€è¾“å…¥ã€‘")
        print(data[0]['input'][:200] + "...")
        print(f"\nã€è¾“å‡ºã€‘")
        print(data[0]['output'][:200] + "...")

def main():
    print("="*60)
    print("ğŸš€ å‡†å¤‡åŒQwenè®­ç»ƒæ•°æ®")
    print("="*60)
    
    # æ•°æ®è·¯å¾„
    data_dir = Path("training_data")
    output_dir = Path("dual_qwen_data")
    output_dir.mkdir(exist_ok=True)
    
    # åŠ è½½åŸå§‹æ•°æ®
    print("\nğŸ“¥ åŠ è½½åŸå§‹æ•°æ®...")
    bert_data = load_json(data_dir / "bert_data.json")
    qwen_data = load_json(data_dir / "qwen_data.json")
    
    print(f"âœ“ BERTæ•°æ®: {len(bert_data)} æ¡")
    print(f"âœ“ Qwenæ•°æ®: {len(qwen_data)} æ¡")
    
    if not bert_data or not qwen_data:
        print("\nâŒ æ•°æ®åŠ è½½å¤±è´¥ï¼Œè¯·æ£€æŸ¥ training_data ç›®å½•")
        return
    
    # å‡†å¤‡å†³ç­–æ•°æ®
    print("\nğŸ”„ å‡†å¤‡ Qwen-Decision è®­ç»ƒæ•°æ®...")
    decision_data = prepare_decision_data(bert_data)
    save_json(decision_data, output_dir / "qwen_decision_train.json")
    analyze_data(decision_data, "Qwen-Decision")
    
    # å‡†å¤‡æé—®æ•°æ®
    print("\nğŸ”„ å‡†å¤‡ Qwen-Question è®­ç»ƒæ•°æ®...")
    question_data = prepare_question_data(qwen_data)
    save_json(question_data, output_dir / "qwen_question_train.json")
    analyze_data(question_data, "Qwen-Question")
    
    # åˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†
    print("\nğŸ”„ åˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†ï¼ˆ90% è®­ç»ƒï¼Œ10% éªŒè¯ï¼‰...")
    
    # Decisionæ•°æ®åˆ’åˆ†
    split_idx = int(len(decision_data) * 0.9)
    decision_train = decision_data[:split_idx]
    decision_val = decision_data[split_idx:]
    
    save_json(decision_train, output_dir / "qwen_decision_train_split.json")
    save_json(decision_val, output_dir / "qwen_decision_val_split.json")
    
    print(f"\nQwen-Decision:")
    print(f"  è®­ç»ƒé›†: {len(decision_train)} æ¡")
    print(f"  éªŒè¯é›†: {len(decision_val)} æ¡")
    
    # Questionæ•°æ®åˆ’åˆ†
    split_idx = int(len(question_data) * 0.9)
    question_train = question_data[:split_idx]
    question_val = question_data[split_idx:]
    
    save_json(question_train, output_dir / "qwen_question_train_split.json")
    save_json(question_val, output_dir / "qwen_question_val_split.json")
    
    print(f"\nQwen-Question:")
    print(f"  è®­ç»ƒé›†: {len(question_train)} æ¡")
    print(f"  éªŒè¯é›†: {len(question_val)} æ¡")
    
    # æ€»ç»“
    print("\n" + "="*60)
    print("âœ… æ•°æ®å‡†å¤‡å®Œæˆï¼")
    print("="*60)
    print(f"\nè¾“å‡ºç›®å½•: {output_dir}/")
    print(f"\næ–‡ä»¶åˆ—è¡¨:")
    print(f"  - qwen_decision_train.json (å®Œæ•´å†³ç­–æ•°æ®)")
    print(f"  - qwen_question_train.json (å®Œæ•´æé—®æ•°æ®)")
    print(f"  - qwen_decision_train_split.json (å†³ç­–è®­ç»ƒé›†)")
    print(f"  - qwen_decision_val_split.json (å†³ç­–éªŒè¯é›†)")
    print(f"  - qwen_question_train_split.json (æé—®è®­ç»ƒé›†)")
    print(f"  - qwen_question_val_split.json (æé—®éªŒè¯é›†)")
    
    print(f"\nä¸‹ä¸€æ­¥:")
    print(f"  1. è¿è¡Œ: python train_qwen_decision.py")
    print(f"  2. è¿è¡Œ: python train_qwen_question.py")
    print(f"  3. ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹è¿›è¡Œæ¨ç†")

if __name__ == "__main__":
    main()


