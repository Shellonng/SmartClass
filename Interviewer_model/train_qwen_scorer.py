"""
è®­ç»ƒQwen-Scoreræ¨¡å‹ï¼ˆè¯„åˆ†+æ ‡ç­¾+è¯„ä»·ç”Ÿæˆï¼‰
ä½¿ç”¨V3ä¼˜åŒ–é…ç½®ï¼šé˜²è¿‡æ‹Ÿåˆ
"""

import json
import torch
import sys
import io
from pathlib import Path
from datasets import Dataset
from transformers import (
    AutoTokenizer,
    AutoModelForCausalLM,
    BitsAndBytesConfig,
    TrainingArguments,
    Trainer,
    DataCollatorForSeq2Seq,
    EarlyStoppingCallback
)
from peft import (
    LoraConfig,
    get_peft_model,
    prepare_model_for_kbit_training,
    TaskType
)
import matplotlib.pyplot as plt
import numpy as np

# ä¿®å¤Windowsæ§åˆ¶å°ç¼–ç 
sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')

# é…ç½®ï¼ˆV3ä¼˜åŒ–ç‰ˆï¼šé˜²è¿‡æ‹Ÿåˆï¼‰
CONFIG = {
    # æ¨¡å‹é…ç½®
    "base_model": "Qwen/Qwen2-1.5B-Instruct",
    "max_length": 1024,
    
    # LoRAé…ç½®ï¼ˆå¢å¼ºæ­£åˆ™åŒ–ï¼‰
    "lora_r": 16,
    "lora_alpha": 32,
    "lora_dropout": 0.15,  # V3: å¢å¼ºæ­£åˆ™åŒ–
    "lora_target_modules": ["q_proj", "k_proj", "v_proj", "o_proj", 
                            "gate_proj", "up_proj", "down_proj"],
    
    # è®­ç»ƒé…ç½®V3ï¼ˆé˜²è¿‡æ‹Ÿåˆï¼‰
    "batch_size": 2,
    "gradient_accumulation": 4,
    "num_epochs": 3,  # V3: ä»5é™è‡³3
    "learning_rate": 1.0e-4,  # V3: é™ä½å­¦ä¹ ç‡
    "warmup_steps": 30,
    "logging_steps": 5,
    "save_steps": 50,  # V3: æ›´é¢‘ç¹ä¿å­˜
    "eval_steps": 10,
    
    # æ—©åœé…ç½®ï¼ˆæ–°å¢ï¼‰
    "early_stopping_patience": 10,
    "early_stopping_threshold": 0.001,
    
    # 4bité‡åŒ–é…ç½®
    "use_4bit": True,
    "bnb_4bit_compute_dtype": torch.float16,
    "bnb_4bit_quant_type": "nf4",
    
    # è·¯å¾„
    "train_data": "dual_qwen_data/qwen_scorer_train_split.json",
    "val_data": "dual_qwen_data/qwen_scorer_val_split.json",
    "output_dir": "checkpoints/qwen_scorer_lora",
}

def print_trainable_parameters(model):
    """æ‰“å°å¯è®­ç»ƒå‚æ•°ä¿¡æ¯"""
    trainable_params = 0
    all_param = 0
    for _, param in model.named_parameters():
        all_param += param.numel()
        if param.requires_grad:
            trainable_params += param.numel()
    
    print(f"\nğŸ“Š æ¨¡å‹å‚æ•°ç»Ÿè®¡:")
    print(f"  å¯è®­ç»ƒå‚æ•°: {trainable_params:,} ({100 * trainable_params / all_param:.2f}%)")
    print(f"  æ€»å‚æ•°: {all_param:,}")
    print(f"  èŠ‚çœå‚æ•°: {100 * (1 - trainable_params / all_param):.2f}%")

def load_data():
    """åŠ è½½è®­ç»ƒæ•°æ®"""
    print(f"\nğŸ“¥ åŠ è½½è®­ç»ƒæ•°æ®...")
    
    with open(CONFIG["train_data"], 'r', encoding='utf-8') as f:
        train_data = json.load(f)
    
    with open(CONFIG["val_data"], 'r', encoding='utf-8') as f:
        val_data = json.load(f)
    
    print(f"âœ“ è®­ç»ƒé›†: {len(train_data)} æ¡")
    print(f"âœ“ éªŒè¯é›†: {len(val_data)} æ¡")
    
    return train_data, val_data

def prepare_dataset(data, tokenizer):
    """å‡†å¤‡æ•°æ®é›†"""
    
    def format_prompt(instruction, input_text, output_text=None):
        """æ ¼å¼åŒ–ä¸ºQwen2å¯¹è¯æ ¼å¼"""
        if output_text:
            # è®­ç»ƒæ—¶åŒ…å«è¾“å‡º
            return f"""<|im_start|>system
{instruction}<|im_end|>
<|im_start|>user
{input_text}<|im_end|>
<|im_start|>assistant
{output_text}<|im_end|>"""
        else:
            # æ¨ç†æ—¶ä¸åŒ…å«è¾“å‡º
            return f"""<|im_start|>system
{instruction}<|im_end|>
<|im_start|>user
{input_text}<|im_end|>
<|im_start|>assistant
"""
    
    formatted_data = []
    for item in data:
        prompt = format_prompt(
            item['instruction'],
            item['input'],
            item['output']
        )
        formatted_data.append({"text": prompt})
    
    return Dataset.from_list(formatted_data)

def tokenize_function(examples, tokenizer):
    """åˆ†è¯å‡½æ•°"""
    result = tokenizer(
        examples["text"],
        truncation=True,
        max_length=CONFIG["max_length"],
        padding=False,
    )
    result["labels"] = result["input_ids"].copy()
    return result

def plot_training_history(log_history, output_path):
    """ç»˜åˆ¶è®­ç»ƒæ›²çº¿"""
    
    # æå–è®­ç»ƒå’ŒéªŒè¯loss
    train_steps = []
    train_losses = []
    eval_steps = []
    eval_losses = []
    
    for entry in log_history:
        if 'loss' in entry and 'step' in entry:
            train_steps.append(entry['step'])
            train_losses.append(entry['loss'])
        if 'eval_loss' in entry and 'step' in entry:
            eval_steps.append(entry['step'])
            eval_losses.append(entry['eval_loss'])
    
    if not train_losses or not eval_losses:
        print("âš ï¸  è­¦å‘Š: æ²¡æœ‰è¶³å¤Ÿçš„æ•°æ®ç»˜åˆ¶è®­ç»ƒæ›²çº¿")
        return
    
    # è®¾ç½®ä¸­æ–‡å­—ä½“
    plt.rcParams['font.sans-serif'] = ['Microsoft YaHei', 'SimHei', 'Arial Unicode MS']
    plt.rcParams['axes.unicode_minus'] = False
    
    fig, ax = plt.subplots(figsize=(12, 7))
    
    # è®­ç»ƒloss
    ax.plot(train_steps, train_losses,
            label='Training Loss',
            color='#2E86AB',
            linewidth=2,
            alpha=0.8)
    
    # éªŒè¯loss
    ax.plot(eval_steps, eval_losses,
            label='Validation Loss',
            color='#A23B72',
            linewidth=2.5,
            marker='o',
            markersize=4,
            alpha=0.9)
    
    # æ ‡è®°æœ€ä½³ç‚¹
    if eval_losses:
        best_idx = np.argmin(eval_losses)
        best_step = eval_steps[best_idx]
        best_loss = eval_losses[best_idx]
        
        ax.scatter([best_step], [best_loss],
                  color='#F18F01',
                  s=200,
                  marker='*',
                  zorder=5,
                  label=f'Best Model (Step {best_step}, Loss {best_loss:.4f})')
    
    ax.set_xlabel('Training Steps', fontsize=12, fontweight='bold')
    ax.set_ylabel('Loss', fontsize=12, fontweight='bold')
    ax.set_title('Qwen-Scorer V3 Training Progress (Anti-Overfitting)',
                 fontsize=14, fontweight='bold', pad=20)
    
    ax.legend(loc='upper right', fontsize=10, framealpha=0.9)
    ax.grid(True, alpha=0.3, linestyle='--')
    
    # æ·»åŠ æ–‡æœ¬æ¡†æ˜¾ç¤ºæœ€ç»ˆæŒ‡æ ‡
    final_train = np.mean(train_losses[-10:]) if len(train_losses) >= 10 else np.mean(train_losses)
    final_eval = eval_losses[-1]
    gap = final_train - final_eval
    
    textstr = f'Final Metrics:\n'
    textstr += f'Train Loss: {final_train:.4f}\n'
    textstr += f'Eval Loss: {final_eval:.4f}\n'
    textstr += f'Gap: {gap:.4f}\n'
    textstr += f'Best Eval: {best_loss:.4f}'
    
    props = dict(boxstyle='round', facecolor='wheat', alpha=0.8)
    ax.text(0.02, 0.98, textstr, transform=ax.transAxes, fontsize=10,
            verticalalignment='top', bbox=props, family='monospace')
    
    plt.tight_layout()
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    print(f"\nâœ“ è®­ç»ƒæ›²çº¿å·²ä¿å­˜: {output_path}")
    plt.close()

def main():
    """ä¸»è®­ç»ƒæµç¨‹"""
    print("="*60)
    print("ğŸš€ è®­ç»ƒ Qwen-Scorer æ¨¡å‹ï¼ˆè¯„åˆ†+è¯„ä»·ç”Ÿæˆï¼‰")
    print("="*60)
    
    # æ£€æŸ¥GPU
    if torch.cuda.is_available():
        print(f"\nâœ“ GPU: {torch.cuda.get_device_name(0)}")
        print(f"âœ“ æ˜¾å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
    else:
        print("\nâš ï¸  è­¦å‘Š: æœªæ£€æµ‹åˆ°GPUï¼Œè®­ç»ƒå°†éå¸¸ç¼“æ…¢")
    
    # åŠ è½½æ•°æ®
    train_data, val_data = load_data()
    
    # åŠ è½½åˆ†è¯å™¨
    print(f"\nğŸ“¥ åŠ è½½åˆ†è¯å™¨...")
    tokenizer = AutoTokenizer.from_pretrained(CONFIG["base_model"])
    
    if tokenizer.pad_token is None:
        tokenizer.pad_token = tokenizer.eos_token
    
    print(f"âœ“ åˆ†è¯å™¨åŠ è½½å®Œæˆ")
    
    # å‡†å¤‡æ•°æ®é›†
    print(f"\nğŸ”„ å¯¹æ•°æ®è¿›è¡Œåˆ†è¯...")
    train_dataset = prepare_dataset(train_data, tokenizer)
    val_dataset = prepare_dataset(val_data, tokenizer)
    
    train_dataset = train_dataset.map(
        lambda x: tokenize_function(x, tokenizer),
        batched=True,
        remove_columns=train_dataset.column_names,
        desc="å¤„ç†è®­ç»ƒé›†"
    )
    
    val_dataset = val_dataset.map(
        lambda x: tokenize_function(x, tokenizer),
        batched=True,
        remove_columns=val_dataset.column_names,
        desc="å¤„ç†éªŒè¯é›†"
    )
    
    print(f"`torch_dtype` is deprecated! Use `dtype` instead!")
    print(f"âœ“ åˆ†è¯å®Œæˆ")
    
    # é…ç½®4bité‡åŒ–
    print(f"\nâš™ï¸  é…ç½®4bité‡åŒ–...")
    bnb_config = BitsAndBytesConfig(
        load_in_4bit=CONFIG["use_4bit"],
        bnb_4bit_compute_dtype=CONFIG["bnb_4bit_compute_dtype"],
        bnb_4bit_quant_type=CONFIG["bnb_4bit_quant_type"],
        bnb_4bit_use_double_quant=True,
    )
    
    # åŠ è½½åŸºåº§æ¨¡å‹
    print(f"\nğŸ“¥ åŠ è½½åŸºåº§æ¨¡å‹: {CONFIG['base_model']}")
    print(f"   ä½¿ç”¨4bité‡åŒ–ä»¥èŠ‚çœæ˜¾å­˜...")
    
    model = AutoModelForCausalLM.from_pretrained(
        CONFIG["base_model"],
        quantization_config=bnb_config,
        device_map="auto",
    )
    
    model = prepare_model_for_kbit_training(model)
    print(f"âœ“ åŸºåº§æ¨¡å‹åŠ è½½å®Œæˆ")
    
    # LoRAé…ç½®
    print(f"\nâš™ï¸  é…ç½®LoRA...")
    lora_config = LoraConfig(
        r=CONFIG["lora_r"],
        lora_alpha=CONFIG["lora_alpha"],
        target_modules=CONFIG["lora_target_modules"],
        lora_dropout=CONFIG["lora_dropout"],
        bias="none",
        task_type=TaskType.CAUSAL_LM
    )
    
    # åº”ç”¨LoRA
    model = get_peft_model(model, lora_config)
    print_trainable_parameters(model)
    
    # è®­ç»ƒå‚æ•°
    print(f"\nâš™ï¸  é…ç½®è®­ç»ƒå‚æ•°...")
    training_args = TrainingArguments(
        output_dir=CONFIG["output_dir"],
        num_train_epochs=CONFIG["num_epochs"],
        per_device_train_batch_size=CONFIG["batch_size"],
        per_device_eval_batch_size=CONFIG["batch_size"],
        gradient_accumulation_steps=CONFIG["gradient_accumulation"],
        learning_rate=CONFIG["learning_rate"],
        warmup_steps=CONFIG["warmup_steps"],
        logging_steps=CONFIG["logging_steps"],
        save_steps=CONFIG["save_steps"],
        eval_steps=CONFIG["eval_steps"],
        eval_strategy="steps",
        save_strategy="steps",
        load_best_model_at_end=True,
        metric_for_best_model="eval_loss",
        greater_is_better=False,
        fp16=True,
        gradient_checkpointing=True,
        optim="paged_adamw_8bit",
        max_grad_norm=0.3,
        weight_decay=0.01,  # V3: L2æ­£åˆ™åŒ–
        logging_dir=f"{CONFIG['output_dir']}/logs",
        report_to="none",
    )
    
    print(f"âœ“ è®­ç»ƒé…ç½® (V3 - é˜²è¿‡æ‹Ÿåˆä¼˜åŒ–):")
    print(f"  - Batch size: {CONFIG['batch_size']}")
    print(f"  - æ¢¯åº¦ç´¯ç§¯: {CONFIG['gradient_accumulation']} (ç­‰æ•ˆbatch={CONFIG['batch_size']*CONFIG['gradient_accumulation']})")
    print(f"  - Epochs: {CONFIG['num_epochs']}")
    print(f"  - Learning rate: {CONFIG['learning_rate']}")
    print(f"  - LoRA dropout: {CONFIG['lora_dropout']}")
    print(f"  - æ—©åœ: patience={CONFIG['early_stopping_patience']}")
    print(f"  - æƒé‡è¡°å‡: 0.01")
    print(f"  - 4bité‡åŒ–: âœ“")
    print(f"  - æ¢¯åº¦æ£€æŸ¥ç‚¹: âœ“")
    print(f"  - é¢„æœŸæ˜¾å­˜: 5-6GB")
    
    # Data Collator
    data_collator = DataCollatorForSeq2Seq(
        tokenizer=tokenizer,
        model=model,
        padding=True
    )
    
    # åˆ›å»ºTrainerï¼ˆæ·»åŠ æ—©åœï¼‰
    print(f"\nğŸ”„ åˆå§‹åŒ–è®­ç»ƒå™¨ï¼ˆå«æ—©åœæœºåˆ¶ï¼‰...")
    
    # æ—©åœå›è°ƒ
    early_stopping = EarlyStoppingCallback(
        early_stopping_patience=CONFIG["early_stopping_patience"],
        early_stopping_threshold=CONFIG["early_stopping_threshold"]
    )
    
    trainer = Trainer(
        model=model,
        args=training_args,
        train_dataset=train_dataset,
        eval_dataset=val_dataset,
        data_collator=data_collator,
        callbacks=[early_stopping],
    )
    
    # å¼€å§‹è®­ç»ƒ
    print(f"\n" + "="*60)
    print("ğŸš€ å¼€å§‹è®­ç»ƒ V3ï¼ˆé˜²è¿‡æ‹Ÿåˆä¼˜åŒ–ç‰ˆï¼‰...")
    print("="*60)
    print(f"\né…ç½®ç‰¹ç‚¹:")
    print(f"  - Epochs: 3ï¼ˆé¿å…è¿‡æ‹Ÿåˆï¼‰")
    print(f"  - Learning Rate: 1.0e-4ï¼ˆç¨³å®šè®­ç»ƒï¼‰")
    print(f"  - LoRA Dropout: 0.15ï¼ˆå¢å¼ºæ­£åˆ™åŒ–ï¼‰")
    print(f"  - æ—©åœ: patience=10")
    print(f"  - æƒé‡è¡°å‡: 0.01ï¼ˆL2æ­£åˆ™ï¼‰")
    print(f"\né¢„è®¡è®­ç»ƒæ—¶é—´: 25-35åˆ†é’Ÿï¼ˆæ•°æ®é‡: {len(train_data)}æ¡ï¼‰")
    print(f"å¯ä»¥ä½¿ç”¨ nvidia-smi ç›‘æ§æ˜¾å­˜ä½¿ç”¨æƒ…å†µ\n")
    
    try:
        trainer.train()
        
        print(f"\n" + "="*60)
        print("âœ… è®­ç»ƒå®Œæˆï¼")
        print("="*60)
        
        # ä¿å­˜æ¨¡å‹
        print(f"\nğŸ’¾ ä¿å­˜æ¨¡å‹...")
        trainer.save_model(CONFIG["output_dir"])
        tokenizer.save_pretrained(CONFIG["output_dir"])
        print(f"âœ“ æ¨¡å‹å·²ä¿å­˜è‡³: {CONFIG['output_dir']}")
        
        # ç»˜åˆ¶è®­ç»ƒæ›²çº¿
        plot_path = Path("plots/qwen_scorer_training.png")
        plot_path.parent.mkdir(exist_ok=True)
        
        if hasattr(trainer.state, 'log_history'):
            plot_training_history(trainer.state.log_history, plot_path)
        
        # æ˜¾ç¤ºæœ€ç»ˆæŒ‡æ ‡
        if trainer.state.log_history:
            final_report = [x for x in trainer.state.log_history if 'train_loss' in x]
            if final_report:
                final_metrics = final_report[-1]
                print(f"\nğŸ“Š æœ€ç»ˆè®­ç»ƒæŒ‡æ ‡:")
                for key, value in final_metrics.items():
                    if isinstance(value, float):
                        print(f"  {key}: {value:.4f}")
                    else:
                        print(f"  {key}: {value}")
        
        print(f"\nğŸ‰ Qwen-Scorer è®­ç»ƒæˆåŠŸï¼")
        
        print(f"\nâœ… ä¸‰ä¸ªQwenæ¨¡å‹è®­ç»ƒå…¨éƒ¨å®Œæˆï¼")
        print(f"\nå·²è®­ç»ƒæ¨¡å‹:")
        print(f"  1. Qwen-Decision (å†³ç­–+æŒ‡å¯¼)")
        print(f"  2. Qwen-Question (æé—®+é‡è¦æ€§)")
        print(f"  3. Qwen-Scorer (è¯„åˆ†+è¯„ä»·) [NEW]")
        
        print(f"\nä¸‹ä¸€æ­¥:")
        print(f"  ä½¿ç”¨: python test_triple_qwen.py è¿›è¡Œå®Œæ•´æµ‹è¯•")
        
    except KeyboardInterrupt:
        print(f"\n\nâš ï¸  è®­ç»ƒè¢«ä¸­æ–­")
        print(f"å·²ä¿å­˜çš„checkpointå¯ä»¥åœ¨ {CONFIG['output_dir']} æ‰¾åˆ°")
    except Exception as e:
        print(f"\n\nâŒ è®­ç»ƒå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()


