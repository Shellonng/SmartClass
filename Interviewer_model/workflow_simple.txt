================================================================================
AI面试系统工作流程演示
================================================================================

【初始状态】
面试官问题: 能说说Python的装饰器吗？
当前话题: Python基础
追问深度: 0

【用户回答】
候选人: 装饰器是Python的高阶函数，我在项目中用它实现了日志记录和权限校验。

================================================================================
【阶段1：RoBERTa评估回答质量】
================================================================================

步骤1.1: 构建评估输入
────────────────────────────────────────────────────────────
RoBERTa输入:
[历史问答]
Q1: 你熟悉哪些Python技术栈？
A1: Flask、Django、装饰器、生成器等
质量: 良好

[当前问答]
问题: 能说说Python的装饰器吗？
回答: 装饰器是Python的高阶函数，我在项目中用它实现了日志记录和权限校验。
流畅度: 0.85
────────────────────────────────────────────────────────────

步骤1.2: RoBERTa模型推理
  -> 多任务推理（分类 + 回归）
  -> 分类logits: [1.2, 2.5, 4.8, 2.1]  (差, 一般, 良好, 优秀)
  -> Softmax后概率: [0.05, 0.15, 0.60, 0.20]
  -> 预测类别: 良好 (index=2, 概率=0.60)
  -> 回归输出: 0.825 * 100 = 82.5分

步骤1.3: RoBERTa输出结果
  [OK] 质量标签: 良好
  [OK] 映射分数: 85
  [OK] 回归分数: 82.5
  [OK] 置信度: 60.0%

[重点] RoBERTa的作用:
  1. 评估回答质量（良好 = 85分）
  2. 这个分数会传给Qwen，影响Qwen的追问方式
  3. 不直接决策，但提供重要的质量信号

================================================================================
【阶段2：BERT决策下一步动作】
================================================================================

步骤2.1: 提取回答特征
  -> 回答长度: 37字
  -> 犹豫词数量: 0个
  -> 犹豫度分数: 0.00
  -> 追问深度: 0
  -> 当前话题: Python基础

步骤2.2: 构建BERT输入
────────────────────────────────────────────────────────────
BERT输入:
能说说Python的装饰器吗？[SEP]装饰器是Python的高阶函数，我在项目中用它实现了日志记录和权限校验。[SEP]追问深度:0 犹豫度:0.00 长度:37字 话题:Python基础
────────────────────────────────────────────────────────────

步骤2.3: BERT模型推理（二分类）
  -> BERT logits: [2.8, -0.5]  (FOLLOW_UP, NEXT_TOPIC)
  -> Softmax后概率: [0.85, 0.15]
  -> 预测: FOLLOW_UP (概率=0.85)

步骤2.4: 推断决策理由
  -> 检查关键词: '项目' [找到], '用过' [未找到]
  -> 回答长度: 37字 < 80字
  -> 匹配规则: '候选者提到了使用场景但缺少细节'

步骤2.5: BERT输出决策
  [OK] 决策动作: FOLLOW_UP
  [OK] 置信度: 85.0%
  [OK] 决策理由: 候选者提到了使用场景但缺少细节，可以继续追问更深入的技术细节
  [OK] 概率分布: FOLLOW_UP=85.0%, NEXT_TOPIC=15.0%

[重点] BERT的作用:
  1. 根据回答内容、长度、犹豫度、追问深度综合决策
  2. 决策：继续追问 or 换话题（二选一）
  3. 不管具体问什么，只管该不该追问
  4. 控制面试节奏，避免过度追问或过早换题

================================================================================
【阶段3：Qwen生成下一个问题】
================================================================================

步骤3.1: 构建Qwen上下文
  -> 上一个问题: 能说说Python的装饰器吗？
  -> 候选人回答: 装饰器是Python的高阶函数，我在项目中用它实现...
  -> 当前话题: Python基础
  -> RoBERTa评分: 85分
  -> BERT决策: FOLLOW_UP

步骤3.2: 根据BERT决策选择生成策略
  -> BERT决策 = FOLLOW_UP
  -> 走追问分支
  -> RoBERTa评分 = 85分
  -> 评分>=80 -> 策略: 候选人回答得不错，可以适当肯定（不要过于客套），然后追问更深入的问题

步骤3.3: 构建Qwen Prompt
────────────────────────────────────────────────────────────
System:
  你是一位经验丰富的Python基础技术面试官，面试风格专业、平和，善于引导候选人展示真实水平。

User:
  你刚才问了候选人："能说说Python的装饰器吗？"
  
  候选人的回答是："装饰器是Python的高阶函数，我在项目中用它实现了日志记录和权限校验。"
  
  候选人回答得不错，可以适当肯定（不要过于客套），然后追问更深入的问题。请生成你的下一个问题或回复。注意：
  - 语气自然，像正常对话
  - 不要使用"非常棒！"、"很好！"这种过于热情的表扬
  - 如果需要肯定，可以说"嗯，理解了"、"可以"、"听起来不错"等
  - 直接问下一个问题，不要啰嗦
  - 长度适中（40-80字）
  
  你的回复：
────────────────────────────────────────────────────────────

步骤3.4: Qwen模型生成
  -> 使用基座模型 (Qwen2-1.5B-Instruct)
  -> 生成参数: max_new_tokens=100, temperature=0.7, top_p=0.9
  -> 生成中...

步骤3.5: Qwen输出新问题
  [OK] 新问题: 嗯，理解了。那在实际项目中，你是怎么处理装饰器的执行顺序问题的？特别是当有多个装饰器叠加的时候？

[重点] Qwen的作用:
  1. 接收BERT决策（FOLLOW_UP）+ RoBERTa评分（85分）
  2. 根据评分决定语气（85分->适当肯定）
  3. 自主生成追问问题（关注装饰器执行顺序）
  4. 确保语气自然（'嗯，理解了'而非'非常棒！'）

================================================================================
【阶段4：更新系统状态】
================================================================================

步骤4.1: 更新追问深度
  -> 追问深度: 0 -> 1

步骤4.2: 保存问答历史
  -> 记录: Q='能说说Python的装饰器吗？...'
  -> 质量: 良好(85分)
  -> 动作: FOLLOW_UP

步骤4.3: 更新当前问题
  -> 新问题: 嗯，理解了。那在实际项目中，你是怎么处理装饰器的执行顺序问题的？特别是当有多个装饰器叠加的时候？

步骤4.4: 生成语音并展示
  -> 调用TTS: text_to_speech('嗯，理解了。那在实际项目中...')
  -> 音频文件: audio/tts_1234.mp3
  -> 展示问题 + 自动播放音频

================================================================================
【流程总结】
================================================================================

三个模型的协作:
  1. RoBERTa评估: '良好(85分)' -> 告诉Qwen回答质量不错
  2. BERT决策: 'FOLLOW_UP(85%置信度)' -> 告诉Qwen要继续追问
  3. Qwen生成: 根据评分(85)和决策(追问) -> 生成有肯定+深入的追问

关键信息流:
  用户回答
    -> RoBERTa: 85分(良好)
    -> BERT: FOLLOW_UP + 理由
    -> Qwen: 接收85分 + FOLLOW_UP -> 生成'嗯，理解了。那...'
    -> 展示新问题

下一轮:
  当前问题: 嗯，理解了。那在实际项目中，你是怎么处理装饰器的执行顺序问题的？特别是当有多个装饰器叠加的时候？
  当前话题: Python基础
  追问深度: 1
  等待用户回答...

================================================================================
[OK] 演示完成！
================================================================================


================================================================================
【补充：三个模型的详细分工】
================================================================================

模型1: RoBERTa (评估者)
──────────────────────────────────────────────────────────────
职责: 评估回答质量
输入: 问题 + 回答 + 历史问答
输出: 质量标签(差/一般/良好/优秀) + 分数(0-100)
作用: 
  - 为Qwen提供回答质量信号
  - 影响Qwen的追问语气和深度
  - 分数高(>=80) -> Qwen肯定+深入追问
  - 分数中(60-80) -> Qwen引导具体化
  - 分数低(<60) -> Qwen换角度或给提示
训练数据: 2000条标注的问答对（每条标注质量和分数）
──────────────────────────────────────────────────────────────

模型2: BERT (决策者)
──────────────────────────────────────────────────────────────
职责: 决策下一步动作（追问 or 换话题）
输入: 问题 + 回答 + 特征(长度/犹豫度/追问深度/话题)
输出: FOLLOW_UP(继续追问) or NEXT_TOPIC(换话题)
决策规则（从训练数据中学到）:
  -> FOLLOW_UP:
     - 回答有内容但不够详细
     - 提到了使用场景但缺少实现细节
     - 追问深度<3
  -> NEXT_TOPIC:
     - 明确表示"不了解"、"没学过"
     - 已追问>=2次仍然模糊
     - 回答过于简短(<20字)
训练数据: 1500条标注的决策样本
──────────────────────────────────────────────────────────────

模型3: Qwen (提问者)
──────────────────────────────────────────────────────────────
职责: 生成下一个问题
输入: BERT决策 + RoBERTa分数 + 对话上下文
输出: 新问题文本

分支1: BERT决策=FOLLOW_UP
  -> 根据RoBERTa分数调整追问方式：
     - 分数>=80：肯定 + 深入追问
     - 分数60-80：引导具体化
     - 分数<60：换角度问

分支2: BERT决策=NEXT_TOPIC
  -> 根据RoBERTa分数调整过渡方式：
     - 分数>=80：积极过渡("已考察充分")
     - 分数<60：友好过渡("我们聊聊其他的")
  -> 从简历技能中选择还没问过的话题

训练方式: 
  - 基座模型: 直接使用Qwen2-1.5B-Instruct，通过Prompt控制
  - LoRA模型: 在2000条合成对话数据上微调（可选）
──────────────────────────────────────────────────────────────


================================================================================
【关键设计亮点】
================================================================================

1. RoBERTa不直接决策，但影响Qwen
   ────────────────────────────────────────────────────────────
   RoBERTa评分 -> 影响Qwen的提示词
   
   if score >= 80:
       feedback_guide = "候选人回答得不错，可以适当肯定，然后追问更深入的问题"
   elif score >= 60:
       feedback_guide = "候选人的回答比较笼统，需要引导他说得更具体"
   else:
       feedback_guide = "候选人的回答不太理想，可以换个角度问，或者给个提示"
   
   # 这个feedback_guide会被放入Qwen的prompt中
   ────────────────────────────────────────────────────────────

2. BERT只做二分类决策，不管问什么
   ────────────────────────────────────────────────────────────
   BERT只输出：FOLLOW_UP or NEXT_TOPIC
   具体问什么问题 -> 完全由Qwen决定
   
   decision = {
       'action': 'FOLLOW_UP',  # 只告诉Qwen要追问
       'reason': '候选者提到了使用场景但缺少细节'  # 给Qwen参考
   }
   ────────────────────────────────────────────────────────────

3. Qwen接收所有信息，自主生成
   ────────────────────────────────────────────────────────────
   context = {
       'last_answer': answer,              # 候选人回答
       'question': current_question,       # 当前问题
       'topic': current_topic,             # 当前话题
       'score': eval_result['current_score'],  # RoBERTa评分
       'skills': resume_skills,            # 简历技能
       'history': qa_history               # 历史问答
   }
   
   # Qwen根据这些信息 + BERT决策 -> 生成合适的问题
   new_question = generate_qwen_question(models, context, decision['action'])
   ────────────────────────────────────────────────────────────

4. 追问深度控制
   ────────────────────────────────────────────────────────────
   防止无限追问同一个话题
   
   if decision['action'] == 'FOLLOW_UP':
       follow_up_depth += 1
       if follow_up_depth >= 3:  # BERT训练时学到：追问3次后通常换题
           # BERT会倾向于输出NEXT_TOPIC
   else:
       follow_up_depth = 0  # 换话题后重置
   ────────────────────────────────────────────────────────────


